{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf90a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "febfdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Sentiment:\n",
    "    NE='NEGATIVE'\n",
    "    NL='NEUTRAL'\n",
    "    PE='POSITIVE'\n",
    "    \n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text=text\n",
    "        self.score=score\n",
    "        self.sentiment=self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score<=2:\n",
    "            return Sentiment.NE\n",
    "        elif self.score==3:\n",
    "            return Sentiment.NL\n",
    "        else:\n",
    "            return Sentiment.PE\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews=reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "    \n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative=list(filter(lambda x:x.sentiment==Sentiment.NE,self.reviews))\n",
    "        positive=list(filter(lambda x:x.sentiment==Sentiment.PE,self.reviews))\n",
    "        positive_shrunk=positive[:len(negative)]\n",
    "        self.reviews=negative+positive_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89634f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "reviews=[]\n",
    "with open('books_small_10000.json') as f:\n",
    "    for line in f:\n",
    "        review=json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "        \n",
    "print(reviews[5].score)\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6334e288",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20a58384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training,test=train_test_split(reviews,test_size=0.33, random_state=42)\n",
    "train_container = ReviewContainer(training)\n",
    "test_container=ReviewContainer(test)\n",
    "\n",
    "train_container.evenly_distribute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3231ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x= train_container.get_text()\n",
    "train_y= train_container.get_sentiment()\n",
    "\n",
    "\n",
    "test_container.evenly_distribute()  #it is important to do it because our training model contains balanced data and our test data doesnt, which impacts the overall accuracy!\n",
    "test_x= train_container.get_text()\n",
    "test_y= train_container.get_sentiment()\n",
    "\n",
    "# print(train_y.count(Sentiment.PE))\n",
    "# print(train_y.count(Sentiment.NE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458edec4",
   "metadata": {},
   "source": [
    "### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba4c9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#vectorizer=CountVectorizer()\n",
    "#vectorizer.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8df8374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scholarly, Enlightening, Educational, Mysticism, Profound and Intriguing are some of the words that best describe Author Stanislaw Kapuscinski&#8217;s book, &#8220;The Key to Immortality.&#8221;I have always been an avid reader of The Gospel of Thomas and am constantly in search of books that capture my attention and teach me in the process, especially as they pertain to different Gospels. The Key to Immortality accomplishes both those avenues in a compelling manner that by far outweighs other books discussing the same Gospel.While I am no theologian by any means, I do consider myself to be very profuse and knowledgeable with topics surrounding the bible, especially the New Testament. Most books I have read are cumbersome and not easy to read which don&#8217;t flow well. Perhaps it&#8217;s because I am a layperson thatis why I have not had much luck finding a book in this genre that truly captivates me from the start. That was not the case with &#8220;The Key to Immortality.&#8221; In this book the pages flowed effortlessly and for me I felt as if the words were written in away that everyone could understand and appreciate.Each of the 114 Logia discussed will present a different turn and outlook on things that will take your breath away and have an impact on how you view not only the Gospel of Thomas, but also your own life.In closing this book was mind-blowing experience that I was happy to discuss and add to my library. I rate it 5 stars!Correction from my last review. I just noticed I used the word, &#34;novel&#34; a few times which would mean this work is fiction, which it is not and was an error on my end. I am reposting to that folks reading this review do not miss out on this amazing read that will last the test of time and have an amazing impact on your life.\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()\n",
    "train_x_vectors=vectorizer.fit_transform(train_x)\n",
    "#print(vectorizer.get_feature_names())\n",
    "\n",
    "test_x_vectors=vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cafa34",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97b638f8",
   "metadata": {},
   "source": [
    " Linear SVM(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8d35f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm=svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors,train_y)\n",
    "\n",
    "test_x[0]\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c94c5f",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35255df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec= DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors,train_y)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21d5ca",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bde88523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb= DecisionTreeClassifier()\n",
    "clf_gnb.fit(train_x_vectors,train_y)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7974ffc",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f44c69e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log=LogisticRegression()\n",
    "clf_log.fit(train_x_vectors,train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23540e4b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80113354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9988532110091743\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm.score(test_x_vectors,test_y))\n",
    "print(clf_dec.score(test_x_vectors,test_y))\n",
    "print(clf_gnb.score(test_x_vectors,test_y))\n",
    "print(clf_log.score(test_x_vectors,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7009e454",
   "metadata": {},
   "source": [
    "### F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4542b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feras\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test_y,clf_svm.predict(test_x_vectors),average=None, labels=[Sentiment.PE, Sentiment.NL, Sentiment.NE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52918de",
   "metadata": {},
   "source": [
    "## Testing our Model(Qualitative Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b125fd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set=['I thoroughly enjoyed this, 5 stars',\"bad book do not buy\",\"horrible waste of time\"]\n",
    "new_test=vectorizer.transform(test_set)\n",
    "\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5114a7",
   "metadata": {},
   "source": [
    "### Tuning our model (with Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below procedure can only be performed on training set!\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'kernel':('linear','rbf'),'C':(1,4,8,16,32)}\n",
    "\n",
    "svc=svm.SVC()\n",
    "clf=GridSearchCV(svc,params,cv=5)\n",
    "clf.fit(train_x_vectors,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1e761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
